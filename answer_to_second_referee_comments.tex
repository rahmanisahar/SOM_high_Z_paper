Reviewer's Comments:

This paper proposes the use of self-organizing maps (1D and 2D) to aid in classifying galaxy spectra.  The revision has addressed several points and improve the clarity of the text.  However, there are several remaining issues.

1. The authors did not address my comment about the significance of the work.  What was learned?  What method is advocated, and what is the evidence for its superiority?

The sentence that was added about 1D vs. 2D maps comes very late in the paper and is quite abstract, stating that the two methods are complementary.  The Introduction should establish the goals of the investigation so the reader understands the purpose of each experiment as well as its significance.
%20170122PB: draft added
-- We have reorganized the last two paragraphs of Section 1 to better describe the goals of the investigation.


The paper claims that "Compared to previous attempts to classify this sample, the self-organizing map approach was able to better classify the spectra which had similarities with more than one template." (abstract), but I cannot find a quantitative comparison with any previous results.  Figure 9 is presented as the result to compare with previous work, but since the previous results are not presented nor summarized, the reader can't tell how they differ.  The paper reports "more precision", but this is not defined; does it mean smaller error bars?  Stronger correlation?  How does this show "better classification"?  To support such a claim, this paper needs to select a performance metric and report on the values achieved in these experiments, compared to other methods.
--- should I put the figure from the previous paper, maybe Noll09 one??! 
% I don't think including the figure from Noll09 will be enough. It's the performance metric that's critical here.

I had suggested comparing the results to a simple nearest-neighbor classification baseline, but this was not addressed.
%--- why could not I find anything about it in the 1st report?:(
%20170122PB: it's there but well-hidden - the sentence which includes "what performance does one get simply by assigning each of the 142 spectra to its closest match from the 12 templates"

The comment about how SOMs provide an ordered clustering of the data (with respect to feature values), which k-means does not, is certainly true.  But the paper must then explain why this is important or valuable.
--- % need comment here

2. Perhaps I have missed it somewhere, but I don't think the paper ever states how exactly the classification of new data is done.  As I understand it, the authors train an SOM using template spectra, then classify new spectra by determining which SOM node is the best fit for the new item and classifying it based on the labeled template spectra that also reside in that node -- but this isn't actually stated anywhere.  Please add text explaining the classification step.  This would probably go in the final paragraph of the introduction and/or a new subsection in section 3 ("Method") - this section describes SOMs and k-means but not how to use either model to classify new data. (i.e., the SOM can't classify anything without knowing the labels of its original data set.  So although it builds the SOM in an unsupervised way, it requires the supervision of the template labels to be able to assign a label to a new item).
-- Added the following paragraph  at the end of section 3.2: %20170122PB: edited for grammar, inserted in paper text. Needs a bit more discussion.
    "As mentioned in the introduction, one of the main advantages of the SOM method  is that the resulting networks can be used to cluster new datasets with no additional training required. 
     New data with the same dimensionality as the original input data can be presented to the already trained network: the SOM algorithm finds the best matching unit considering the weight of nodes in the trained network and each vector from the new data set.
     The winner node determines the place of each new vector on the SOM.
     Based on the location of the new vectors on the SOM, they can be compared with the original data set. %20170122PB: unclear what "they" refers to
     Sections~\ref{sec: 1Dv} and ~\ref{sec: 2D} show the results of galaxy spectral classifications using networks trained on template spectra."

On page 2, lines 29-31, the authors added this text: "An SOM can be trained without supervision and its results used to classify other data. Therefore, this method can be considered as (semi)-supervised." As written, the phrase "this method" seems to refer to SOMs (so the statement wouldn't be true - SOMs are fully unsupervised), but I think instead the authors' proposed method (of building an SOM and then applying it to classify new data, using labels on the SOM-grouped data) is what is meant.  Please clarify.
-- Changed to: %20170122PB: edited for grammar, inserted in paper text
    "The training of a self-organizing map is fully unsupervised.
     Using the resulting map as a template to classify other data requires labelling the output, which is why some groups consider self-organizing maps to be a (semi)-supervised method."

3. The inclusion of k-means helps give useful context to this work. Figure 10 shows a head-to-head comparison of k-means and SOM applied to the 12 templates using 4 clusters/nodes.  But I can't tell which one is better.  The text states that they are similar but "show discrepancies for spectra types between the extreme cases".  Which ones?  How can I tell from this figure?
-- % need a comment here

At the bottom of page 10, the paper states: "The other difference between these two methods is that the network created by the SOM method can be used to classify the other spectra, while for the K-means clusters they can only be used for one set of data."  This isn't true.  (The paper itself points out that SOM reduces to k-means if the weight on the neighborhood function goes to 0, so you should be able to use the result in the same way.)  You can (and should, to do a direct comparison) use the clusters just like you used the SOM nodes - for a new data point, assign it to the most similar cluster center, then assign the template label from the original data used to construct the clusters.
--- I do not know how to do that!
% for each spectrum to be classified, compute the distance (in whatever metric we end up using)
% between the spectrum and the K cluster centres. Spectrum is classified as belonging to whatever cluster results in the smallest distance.

To analyze the 142 galaxies, the SOM and k-means experiments used different methodology and so are difficult to compare or understand. It seems that for k-means, the authors clustered the 142 sample galaxies and then classified the mean spectrum in each cluster and reported how well that did.  But for the SOM, the authors constructed the SOM based on the 12 templates from K96 and then assigned classes to individual new spectra (not the nodes).  This doesn't seem comparable.  Please use the same methodology in both cases.
--- again I do not know how to used the clusters classified based on template to classify new data sets.
% this is a fair comment - need to think more about how to compare

Further, k-means and the SOM used different distance functions (Euclidean vs. spectral angle distance) when operating on the same data.  Differences in results could simply be due to this change.  The authors' explanation for this choice does not make sense to me.
--- We have results from the Euclidean distance for the K-means! But I steel think because of the way SOM operates it is better to use SAD! Or maybe describe it better!

The text says that Figure 11 shows "the best and the worst fitting results among the 22 clusters" (for k-means) but instead it seems to show the best-fit for two clusters (9 and 22) which both look pretty good.  The text implies that Fig 11 (right) is a poor match, but it looks very good.  Please explain.
--- We apologize: this was a typo with "right" and "left" switched.

%%%%! I wrote right and left wrong again:( I should be extra careful on this one.

4. If k-means is retained, the way it is presented needs improvement. The description of k-means clustering in section 1 is a nice addition, but the comparison between k-means and SOM is confusing and wordy. K-means optimizes a partition of the data based on distance in the feature space only.  SOMs operate on a combination of distance in feature space and distance in the resulting low-dimensional map.  I am not sure how this achieves "smoothing", nor whether this is an important detail (the paper never mentions it again).  I recommend explaining what is meant here and why a "smooth" solution is better, or omitting this detail.  Explaining how SOM can be reduced to k-means is a good addition.
% PB: I edited this a bit, but not quite done as of 20170123 - need to talk about the smoothing part.

Please a add citation to the original k-means algorithm (e.g., MacQueen, 1967) when it is first mentioned (in addition to citing people who've used the algorithm).
-- Added the proper citation.

Section 3.3 outlines the k-means method that is used in the experiments.  The language here appears to be more informal and less polished than that which describes the SOM method.  To explain k-means with the same level of detail, it would be appropriate to show the objective function that is employed and to explain that it uses an alternating optimization to assign points to centroids and then update the centroids, iterating until... what?  (There are different termination conditions used by different implementations, so it would be useful to indicate here what the matlab method does.)

--- After attending to the #3 %(PB: I'll help with the language part)